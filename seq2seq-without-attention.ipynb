{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9fe067c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:32.880795Z",
     "iopub.status.busy": "2024-05-26T02:40:32.879949Z",
     "iopub.status.idle": "2024-05-26T02:40:40.958969Z",
     "shell.execute_reply": "2024-05-26T02:40:40.958130Z"
    },
    "papermill": {
     "duration": 8.095232,
     "end_time": "2024-05-26T02:40:40.961359",
     "exception": false,
     "start_time": "2024-05-26T02:40:32.866127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b27aa79c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:40.988084Z",
     "iopub.status.busy": "2024-05-26T02:40:40.987032Z",
     "iopub.status.idle": "2024-05-26T02:40:41.038070Z",
     "shell.execute_reply": "2024-05-26T02:40:41.037148Z"
    },
    "papermill": {
     "duration": 0.0661,
     "end_time": "2024-05-26T02:40:41.040220",
     "exception": false,
     "start_time": "2024-05-26T02:40:40.974120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ece674",
   "metadata": {
    "papermill": {
     "duration": 0.011714,
     "end_time": "2024-05-26T02:40:41.064089",
     "exception": false,
     "start_time": "2024-05-26T02:40:41.052375",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a73366b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:41.092022Z",
     "iopub.status.busy": "2024-05-26T02:40:41.091681Z",
     "iopub.status.idle": "2024-05-26T02:40:41.140746Z",
     "shell.execute_reply": "2024-05-26T02:40:41.139747Z"
    },
    "papermill": {
     "duration": 0.066769,
     "end_time": "2024-05-26T02:40:41.142880",
     "exception": false,
     "start_time": "2024-05-26T02:40:41.076111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Nepali</th>\n",
       "      <th>Attribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who?</td>\n",
       "      <td>को?</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hide.</td>\n",
       "      <td>लुकाउनुहोस्।</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hide.</td>\n",
       "      <td>लुक।</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stay.</td>\n",
       "      <td>बस्नुहोस्।</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hello!</td>\n",
       "      <td>नमस्ते!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  English        Nepali                                        Attribution\n",
       "0    Who?           को?  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "1   Hide.  लुकाउनुहोस्।  CC-BY 2.0 (France) Attribution: tatoeba.org #8...\n",
       "2   Hide.          लुक।  CC-BY 2.0 (France) Attribution: tatoeba.org #8...\n",
       "3   Stay.    बस्नुहोस्।  CC-BY 2.0 (France) Attribution: tatoeba.org #8...\n",
       "4  Hello!       नमस्ते!  CC-BY 2.0 (France) Attribution: tatoeba.org #3..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "# '\\t' is the delimiter used in the file, indicating that columns are separated by tabs\n",
    "df = pd.read_csv('/kaggle/input/english-to-nepali-text/npi.txt', delimiter='\\t', header=None, names=['English', 'Nepali', 'Attribution'])\n",
    "\n",
    "# This is done to verify that the data has been loaded correctly\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6d0c23d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:41.170773Z",
     "iopub.status.busy": "2024-05-26T02:40:41.170433Z",
     "iopub.status.idle": "2024-05-26T02:40:41.179112Z",
     "shell.execute_reply": "2024-05-26T02:40:41.178237Z"
    },
    "papermill": {
     "duration": 0.025287,
     "end_time": "2024-05-26T02:40:41.181261",
     "exception": false,
     "start_time": "2024-05-26T02:40:41.155974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop Attribution column as it it irrelevant\n",
    "df.drop(columns=['Attribution'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c41f4146",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:41.208345Z",
     "iopub.status.busy": "2024-05-26T02:40:41.207523Z",
     "iopub.status.idle": "2024-05-26T02:40:41.217082Z",
     "shell.execute_reply": "2024-05-26T02:40:41.216161Z"
    },
    "papermill": {
     "duration": 0.025592,
     "end_time": "2024-05-26T02:40:41.219261",
     "exception": false,
     "start_time": "2024-05-26T02:40:41.193669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Nepali</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who?</td>\n",
       "      <td>को?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hide.</td>\n",
       "      <td>लुकाउनुहोस्।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hide.</td>\n",
       "      <td>लुक।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stay.</td>\n",
       "      <td>बस्नुहोस्।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hello!</td>\n",
       "      <td>नमस्ते!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  English        Nepali\n",
       "0    Who?           को?\n",
       "1   Hide.  लुकाउनुहोस्।\n",
       "2   Hide.          लुक।\n",
       "3   Stay.    बस्नुहोस्।\n",
       "4  Hello!       नमस्ते!"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new dataframe with only english (source) and nepali (target) sentences\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d43b200",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:41.247241Z",
     "iopub.status.busy": "2024-05-26T02:40:41.246896Z",
     "iopub.status.idle": "2024-05-26T02:40:41.252775Z",
     "shell.execute_reply": "2024-05-26T02:40:41.251829Z"
    },
    "papermill": {
     "duration": 0.021311,
     "end_time": "2024-05-26T02:40:41.254733",
     "exception": false,
     "start_time": "2024-05-26T02:40:41.233422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2689"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check to see how many rows of data we have\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a36cc978",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:41.281409Z",
     "iopub.status.busy": "2024-05-26T02:40:41.281071Z",
     "iopub.status.idle": "2024-05-26T02:40:41.287804Z",
     "shell.execute_reply": "2024-05-26T02:40:41.286940Z"
    },
    "papermill": {
     "duration": 0.022408,
     "end_time": "2024-05-26T02:40:41.289713",
     "exception": false,
     "start_time": "2024-05-26T02:40:41.267305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_sentence(s):\n",
    "    \"\"\"\n",
    "    Preprocesses a given sentence by converting it to lowercase, adding spaces around punctuation marks, \n",
    "    removing special characters, digits, and extra spaces, and stripping leading and trailing whitespaces.\n",
    "    \n",
    "    Args:\n",
    "        s (str): The input sentence to be preprocessed.\n",
    "        \n",
    "    Returns:\n",
    "        str: The preprocessed sentence.\n",
    "    \"\"\"\n",
    "    # Convert the sentence to lowercase\n",
    "    s = s.lower()\n",
    "    \n",
    "    # Add spaces around punctuation marks like periods, question marks, exclamation marks, commas, and other specific punctuation marks used in Nepali\n",
    "    s = re.sub(r\"([?.!।,])\", r\" \\1 \", s)\n",
    "    \n",
    "    # Remove special characters like '@' and '#'\n",
    "    s = re.sub(r'[@#]', '', s)\n",
    "    \n",
    "    # Remove digits from the sentence\n",
    "    s = re.sub(r'\\d+', '', s)\n",
    "    \n",
    "    # Replace multiple spaces with a single space\n",
    "    s = re.sub(r'[\" \"]+', \" \", s)\n",
    "    \n",
    "    # Remove leading and trailing whitespaces\n",
    "    s = s.strip()\n",
    "    \n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50be9f79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:41.316930Z",
     "iopub.status.busy": "2024-05-26T02:40:41.316583Z",
     "iopub.status.idle": "2024-05-26T02:40:41.323191Z",
     "shell.execute_reply": "2024-05-26T02:40:41.322332Z"
    },
    "papermill": {
     "duration": 0.022615,
     "end_time": "2024-05-26T02:40:41.325142",
     "exception": false,
     "start_time": "2024-05-26T02:40:41.302527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_word_list(x):\n",
    "    \"\"\"\n",
    "    Tokenizes a list of sentences and creates a vocabulary dictionary.\n",
    "\n",
    "    Args:\n",
    "        x (list): A list of strings where each string represents a sentence.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - numpy.ndarray: A NumPy array of tokenized representations of input sentences.\n",
    "                             Each sentence in the input list is tokenized into a sequence of integers.\n",
    "                             The output array is of dtype=object because it's a list of lists.\n",
    "            - dict: A dictionary that maps words to their integer indices in the vocabulary.\n",
    "                    Special tokens '<pad>' and '<unk>' are included in the vocabulary for padding\n",
    "                    and unknown words, respectively.\n",
    "    \"\"\"\n",
    "    # Build the word list from the training data\n",
    "    word_list = [word for sent in x for word in sent.split()]\n",
    "\n",
    "    # Count word frequencies\n",
    "    corpus_ = Counter(word_list)\n",
    "\n",
    "    # Create the one-hot dictionary\n",
    "    vocab = {w: i + 2 for i, (w, _) in enumerate(corpus_.items())}  # Start indexing from 2 (0 reserved for padding, 1 for unknown word)\n",
    "    vocab['<pad>'] = 0  # Padding token\n",
    "    vocab['<unk>'] = 1  # Unknown word token\n",
    "\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af5f6b3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:41.352928Z",
     "iopub.status.busy": "2024-05-26T02:40:41.352018Z",
     "iopub.status.idle": "2024-05-26T02:40:41.357469Z",
     "shell.execute_reply": "2024-05-26T02:40:41.356584Z"
    },
    "papermill": {
     "duration": 0.021159,
     "end_time": "2024-05-26T02:40:41.359426",
     "exception": false,
     "start_time": "2024-05-26T02:40:41.338267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(x, vocab):\n",
    "    # Tokenize the training data\n",
    "    final_list = []\n",
    "    for sent in x:\n",
    "        tokenized_sent = [vocab.get(word, 1) for word in sent.split()]  # Use vocab.get() to handle unknown words\n",
    "        final_list.append(tokenized_sent)\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c0cc86f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:41.385569Z",
     "iopub.status.busy": "2024-05-26T02:40:41.385275Z",
     "iopub.status.idle": "2024-05-26T02:40:41.390168Z",
     "shell.execute_reply": "2024-05-26T02:40:41.389303Z"
    },
    "papermill": {
     "duration": 0.020263,
     "end_time": "2024-05-26T02:40:41.392060",
     "exception": false,
     "start_time": "2024-05-26T02:40:41.371797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_inverse_vocab(vocab):\n",
    "    \"\"\"\n",
    "    Create an inverse vocabulary mapping from a given vocabulary.\n",
    "    \n",
    "    Args:\n",
    "    - vocab (dict): Vocabulary mapping (word to token).\n",
    "    \n",
    "    Returns:\n",
    "    - Inverse vocabulary mapping (token to word).\n",
    "    \"\"\"\n",
    "    inv_vocab = {token: word for word, token in vocab.items()}\n",
    "    return inv_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d799c2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:41.418092Z",
     "iopub.status.busy": "2024-05-26T02:40:41.417808Z",
     "iopub.status.idle": "2024-05-26T02:40:41.509757Z",
     "shell.execute_reply": "2024-05-26T02:40:41.508849Z"
    },
    "papermill": {
     "duration": 0.107695,
     "end_time": "2024-05-26T02:40:41.512043",
     "exception": false,
     "start_time": "2024-05-26T02:40:41.404348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessed_english = df.loc[:, 'English'].apply(preprocess_sentence)\n",
    "preprocessed_nepali = df.loc[:, 'Nepali'].apply(preprocess_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f1222b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:41.539226Z",
     "iopub.status.busy": "2024-05-26T02:40:41.538886Z",
     "iopub.status.idle": "2024-05-26T02:40:41.546138Z",
     "shell.execute_reply": "2024-05-26T02:40:41.545237Z"
    },
    "papermill": {
     "duration": 0.023254,
     "end_time": "2024-05-26T02:40:41.548138",
     "exception": false,
     "start_time": "2024-05-26T02:40:41.524884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      who ?\n",
       "1     hide .\n",
       "2     hide .\n",
       "3     stay .\n",
       "4    hello !\n",
       "Name: English, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check to see new preprocessed sentences\n",
    "preprocessed_english.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad890d46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:41.574895Z",
     "iopub.status.busy": "2024-05-26T02:40:41.574606Z",
     "iopub.status.idle": "2024-05-26T02:40:41.581771Z",
     "shell.execute_reply": "2024-05-26T02:40:41.580876Z"
    },
    "papermill": {
     "duration": 0.023184,
     "end_time": "2024-05-26T02:40:41.583874",
     "exception": false,
     "start_time": "2024-05-26T02:40:41.560690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             को ?\n",
       "1    लुकाउनुहोस् ।\n",
       "2            लुक ।\n",
       "3      बस्नुहोस् ।\n",
       "4         नमस्ते !\n",
       "Name: Nepali, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check to see new preprocessed sentences\n",
    "preprocessed_nepali.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53fdf41c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:41.611795Z",
     "iopub.status.busy": "2024-05-26T02:40:41.611468Z",
     "iopub.status.idle": "2024-05-26T02:40:41.620586Z",
     "shell.execute_reply": "2024-05-26T02:40:41.619708Z"
    },
    "papermill": {
     "duration": 0.024685,
     "end_time": "2024-05-26T02:40:41.622532",
     "exception": false,
     "start_time": "2024-05-26T02:40:41.597847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add <sos> and <eos> token for all sentences\n",
    "nepali_sentences_preprocessed = preprocessed_nepali.apply(lambda x: (' ').join(['<sos>', x, '<eos>']))\n",
    "english_sentences_preprocessed = preprocessed_english.apply(lambda x: (' ').join(['<sos>', x, '<eos>']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d825295b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:41.650922Z",
     "iopub.status.busy": "2024-05-26T02:40:41.650115Z",
     "iopub.status.idle": "2024-05-26T02:40:41.657287Z",
     "shell.execute_reply": "2024-05-26T02:40:41.656334Z"
    },
    "papermill": {
     "duration": 0.023547,
     "end_time": "2024-05-26T02:40:41.659638",
     "exception": false,
     "start_time": "2024-05-26T02:40:41.636091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             <sos> को ? <eos>\n",
       "1    <sos> लुकाउनुहोस् । <eos>\n",
       "2            <sos> लुक । <eos>\n",
       "3      <sos> बस्नुहोस् । <eos>\n",
       "4         <sos> नमस्ते ! <eos>\n",
       "5        <sos> मुस्कान । <eos>\n",
       "Name: Nepali, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check to see tokens\n",
    "nepali_sentences_preprocessed.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3eb4e8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:41.687818Z",
     "iopub.status.busy": "2024-05-26T02:40:41.687520Z",
     "iopub.status.idle": "2024-05-26T02:40:41.694366Z",
     "shell.execute_reply": "2024-05-26T02:40:41.693506Z"
    },
    "papermill": {
     "duration": 0.022415,
     "end_time": "2024-05-26T02:40:41.696214",
     "exception": false,
     "start_time": "2024-05-26T02:40:41.673799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      <sos> who ? <eos>\n",
       "1     <sos> hide . <eos>\n",
       "2     <sos> hide . <eos>\n",
       "3     <sos> stay . <eos>\n",
       "4    <sos> hello ! <eos>\n",
       "5    <sos> smile . <eos>\n",
       "Name: English, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check to see tokens\n",
    "english_sentences_preprocessed.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b16222e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:41.724196Z",
     "iopub.status.busy": "2024-05-26T02:40:41.723885Z",
     "iopub.status.idle": "2024-05-26T02:40:41.742127Z",
     "shell.execute_reply": "2024-05-26T02:40:41.741262Z"
    },
    "papermill": {
     "duration": 0.03487,
     "end_time": "2024-05-26T02:40:41.744030",
     "exception": false,
     "start_time": "2024-05-26T02:40:41.709160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "english_vocab = create_word_list(english_sentences_preprocessed)\n",
    "nepali_vocab = create_word_list(nepali_sentences_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "442380c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:41.770881Z",
     "iopub.status.busy": "2024-05-26T02:40:41.770600Z",
     "iopub.status.idle": "2024-05-26T02:40:41.775226Z",
     "shell.execute_reply": "2024-05-26T02:40:41.774349Z"
    },
    "papermill": {
     "duration": 0.02035,
     "end_time": "2024-05-26T02:40:41.777459",
     "exception": false,
     "start_time": "2024-05-26T02:40:41.757109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique English words in our vocabulary 2000\n",
      "Index for the word 'tom' in the english vocab dict: 16\n"
     ]
    }
   ],
   "source": [
    "# check the length of English Vocab and print index some words\n",
    "print(f\"Unique English words in our vocabulary {len(english_vocab)}\")\n",
    "print(f\"Index for the word 'tom' in the english vocab dict: {english_vocab['tom']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86c384a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:41.805051Z",
     "iopub.status.busy": "2024-05-26T02:40:41.804781Z",
     "iopub.status.idle": "2024-05-26T02:40:41.809069Z",
     "shell.execute_reply": "2024-05-26T02:40:41.808230Z"
    },
    "papermill": {
     "duration": 0.020303,
     "end_time": "2024-05-26T02:40:41.811068",
     "exception": false,
     "start_time": "2024-05-26T02:40:41.790765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Nepali words in our vocabulary 3060\n",
      "Index for the word '।' in the english vocab dict: 7\n"
     ]
    }
   ],
   "source": [
    "# check the length of Nepali Vocab and print index some words\n",
    "print(f\"Unique Nepali words in our vocabulary {len(nepali_vocab)}\")\n",
    "print(f\"Index for the word '।' in the english vocab dict: {nepali_vocab['।']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fe4c18b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:41.838579Z",
     "iopub.status.busy": "2024-05-26T02:40:41.838281Z",
     "iopub.status.idle": "2024-05-26T02:40:41.843441Z",
     "shell.execute_reply": "2024-05-26T02:40:41.842495Z"
    },
    "papermill": {
     "duration": 0.02128,
     "end_time": "2024-05-26T02:40:41.845394",
     "exception": false,
     "start_time": "2024-05-26T02:40:41.824114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a inverse of out english and nepali vocab dictionaries mapping tokens to words, which will be \n",
    "# later used for decoding translations\n",
    "inv_nepali = create_inverse_vocab(nepali_vocab)\n",
    "inv_english = create_inverse_vocab(english_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5f10a28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:41.873317Z",
     "iopub.status.busy": "2024-05-26T02:40:41.872916Z",
     "iopub.status.idle": "2024-05-26T02:40:41.882041Z",
     "shell.execute_reply": "2024-05-26T02:40:41.881299Z"
    },
    "papermill": {
     "duration": 0.025714,
     "end_time": "2024-05-26T02:40:41.884171",
     "exception": false,
     "start_time": "2024-05-26T02:40:41.858457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split data into training and testing set\n",
    "X_train_eng, X_test_eng, y_train_nep, y_test_nep = train_test_split(english_sentences_preprocessed, nepali_sentences_preprocessed, test_size = 0.1, random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0650cf54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:41.912204Z",
     "iopub.status.busy": "2024-05-26T02:40:41.911848Z",
     "iopub.status.idle": "2024-05-26T02:40:41.934488Z",
     "shell.execute_reply": "2024-05-26T02:40:41.933487Z"
    },
    "papermill": {
     "duration": 0.038694,
     "end_time": "2024-05-26T02:40:41.936661",
     "exception": false,
     "start_time": "2024-05-26T02:40:41.897967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenize the training and testing data by converting the words in the sentences to their respective\n",
    "# index in the english and nepali vocab\n",
    "english_tokens_train = tokenize(X_train_eng, english_vocab)\n",
    "english_tokens_test = tokenize(X_test_eng, english_vocab)\n",
    "\n",
    "nepali_tokens_train = tokenize(y_train_nep, nepali_vocab)\n",
    "nepali_tokens_test = tokenize(y_test_nep, nepali_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb035ceb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:41.964598Z",
     "iopub.status.busy": "2024-05-26T02:40:41.964286Z",
     "iopub.status.idle": "2024-05-26T02:40:41.970848Z",
     "shell.execute_reply": "2024-05-26T02:40:41.969932Z"
    },
    "papermill": {
     "duration": 0.023016,
     "end_time": "2024-05-26T02:40:41.973011",
     "exception": false,
     "start_time": "2024-05-26T02:40:41.949995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nepali Sentence: <sos> के तिमी हामीले तिमीलाई मद्दत गरुन भन्ने चाहान्छौ ? <eos>\n",
      "English Sentence: <sos> do you want us to help you ? <eos>\n",
      "Tokenizer, vocabulary and inverse vocabs are working as intended\n"
     ]
    }
   ],
   "source": [
    "# conducting a test to check whether the tokenizer, vocabs and inv tokens work as intended\n",
    "\n",
    "\n",
    "nepali_sentence = \" \".join([inv_nepali[token_id] for token_id in nepali_tokens_train[3]])\n",
    "english_sentence = \" \".join([inv_english[token_id] for token_id in english_tokens_train[3]])\n",
    "\n",
    "# Print the concatenated sentences\n",
    "print(\"Nepali Sentence:\", nepali_sentence)\n",
    "print(\"English Sentence:\", english_sentence)\n",
    "\n",
    "assert nepali_sentence == '<sos> के तिमी हामीले तिमीलाई मद्दत गरुन भन्ने चाहान्छौ ? <eos>', 'tokenizer or nepali vocabulary or inv nepali vocab is problamatic'\n",
    "assert english_sentence == '<sos> do you want us to help you ? <eos>', 'tokenizer or english vocabulary or inv english vocab is problamatic'\n",
    "\n",
    "print('Tokenizer, vocabulary and inverse vocabs are working as intended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98041112",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:42.000854Z",
     "iopub.status.busy": "2024-05-26T02:40:42.000521Z",
     "iopub.status.idle": "2024-05-26T02:40:42.277933Z",
     "shell.execute_reply": "2024-05-26T02:40:42.276963Z"
    },
    "papermill": {
     "duration": 0.294318,
     "end_time": "2024-05-26T02:40:42.280350",
     "exception": false,
     "start_time": "2024-05-26T02:40:41.986032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    2420.000000\n",
       "mean        8.773554\n",
       "std         2.289858\n",
       "min         4.000000\n",
       "25%         7.000000\n",
       "50%         8.000000\n",
       "75%        10.000000\n",
       "max        29.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking to see the maximum length of sequences in the english tokens\n",
    "rev_len = [len(i) for i in english_tokens_train]\n",
    "pd.Series(rev_len).hist()\n",
    "plt.show()\n",
    "pd.Series(rev_len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bec4ed4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:42.310792Z",
     "iopub.status.busy": "2024-05-26T02:40:42.310472Z",
     "iopub.status.idle": "2024-05-26T02:40:42.317142Z",
     "shell.execute_reply": "2024-05-26T02:40:42.316234Z"
    },
    "papermill": {
     "duration": 0.02374,
     "end_time": "2024-05-26T02:40:42.319059",
     "exception": false,
     "start_time": "2024-05-26T02:40:42.295319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def padding_(sentences, seq_len):\n",
    "    \"\"\"\n",
    "    Pads or truncates a list of sentences to a specified sequence length.\n",
    "\n",
    "    Args:\n",
    "        sentences (list of lists): A list where each element is a list representing a sentence with tokenized words.\n",
    "        seq_len (int): The desired sequence length for padding or truncation.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A 2D NumPy array of shape (num_sentences, seq_len).\n",
    "                       Each row represents a sentence with padded or truncated tokens.\n",
    "                       If the original sentence length is greater than seq_len, it is truncated;\n",
    "                       if it is less than seq_len, it is padded with zeros.\n",
    "    \"\"\"\n",
    "    # Initialize a NumPy array to store the padded or truncated sentences\n",
    "    features = np.zeros((len(sentences), seq_len), dtype=int)\n",
    "    \n",
    "    # Iterate over each sentence in the input list\n",
    "    for ii, review in enumerate(sentences):\n",
    "        # Check if the length of the sentence is not zero\n",
    "        if len(review) != 0:\n",
    "            # If the length of the sentence is less than seq_len, pad it with zeros\n",
    "            # If it is greater than seq_len, truncate it\n",
    "            features[ii, :len(review)] = np.array(review)[:seq_len]\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fdce760b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:42.392861Z",
     "iopub.status.busy": "2024-05-26T02:40:42.392487Z",
     "iopub.status.idle": "2024-05-26T02:40:42.417639Z",
     "shell.execute_reply": "2024-05-26T02:40:42.416864Z"
    },
    "papermill": {
     "duration": 0.042156,
     "end_time": "2024-05-26T02:40:42.419786",
     "exception": false,
     "start_time": "2024-05-26T02:40:42.377630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pad all the tokenized sentences for batch processing to same sequence length ie 25\n",
    "x_train_pad_eng = padding_(english_tokens_train,25)\n",
    "x_test_pad_eng = padding_(english_tokens_test,25)\n",
    "y_train_pad_nep = padding_(nepali_tokens_train,25)\n",
    "y_test_pad_nep = padding_(nepali_tokens_test,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b032b29f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:42.448984Z",
     "iopub.status.busy": "2024-05-26T02:40:42.448661Z",
     "iopub.status.idle": "2024-05-26T02:40:42.453402Z",
     "shell.execute_reply": "2024-05-26T02:40:42.452523Z"
    },
    "papermill": {
     "duration": 0.022075,
     "end_time": "2024-05-26T02:40:42.455895",
     "exception": false,
     "start_time": "2024-05-26T02:40:42.433820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2420, 25)\n",
      "(269, 25)\n",
      "(2420, 25)\n",
      "(269, 25)\n"
     ]
    }
   ],
   "source": [
    "# check padding\n",
    "print(x_train_pad_eng.shape)\n",
    "print(x_test_pad_eng.shape)\n",
    "print(y_train_pad_nep.shape)\n",
    "print(y_test_pad_nep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20ff6683",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:42.484835Z",
     "iopub.status.busy": "2024-05-26T02:40:42.484511Z",
     "iopub.status.idle": "2024-05-26T02:40:42.499087Z",
     "shell.execute_reply": "2024-05-26T02:40:42.498304Z"
    },
    "papermill": {
     "duration": 0.031527,
     "end_time": "2024-05-26T02:40:42.501101",
     "exception": false,
     "start_time": "2024-05-26T02:40:42.469574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(x_train_pad_eng), torch.from_numpy(y_train_pad_nep))\n",
    "valid_data = TensorDataset(torch.from_numpy(x_test_pad_eng), torch.from_numpy(y_test_pad_nep))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 50\n",
    "\n",
    "# create DataLoader for model training and testing of dimensions 50 x 25 ( batch_size x sequence_length)\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "968e8209",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:42.530553Z",
     "iopub.status.busy": "2024-05-26T02:40:42.530227Z",
     "iopub.status.idle": "2024-05-26T02:40:42.578648Z",
     "shell.execute_reply": "2024-05-26T02:40:42.577459Z"
    },
    "papermill": {
     "duration": 0.065291,
     "end_time": "2024-05-26T02:40:42.580828",
     "exception": false,
     "start_time": "2024-05-26T02:40:42.515537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size: torch.Size([50, 25])\n",
      "Sample target size: torch.Size([50, 25])\n"
     ]
    }
   ],
   "source": [
    "# obtain one batch of training data\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = next(dataiter)\n",
    "\n",
    "\n",
    "# check the dimensions for each batch\n",
    "print(f'Sample input size: {sample_x.size()}')\n",
    "print(f'Sample target size: {sample_y.size()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acb4083",
   "metadata": {
    "papermill": {
     "duration": 0.01338,
     "end_time": "2024-05-26T02:40:42.608550",
     "exception": false,
     "start_time": "2024-05-26T02:40:42.595170",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b70738e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:42.638252Z",
     "iopub.status.busy": "2024-05-26T02:40:42.637867Z",
     "iopub.status.idle": "2024-05-26T02:40:42.646642Z",
     "shell.execute_reply": "2024-05-26T02:40:42.645694Z"
    },
    "papermill": {
     "duration": 0.026166,
     "end_time": "2024-05-26T02:40:42.648695",
     "exception": false,
     "start_time": "2024-05-26T02:40:42.622529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout = 0.5):\n",
    "        \"\"\"\n",
    "        Encoder module of a sequence-to-sequence model.\n",
    "        \n",
    "        Args:\n",
    "            input_dim (int): The size of the input vocabulary.\n",
    "            emb_dim (int): The dimensionality of the embedding layer.\n",
    "            hid_dim (int): The dimensionality of the hidden states.\n",
    "            n_layers (int): The number of layers in the LSTM.\n",
    "            dropout (float): The dropout probability.\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # Initialize encoder attributes\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # Embedding layer to convert input tokens into dense vectors\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=0)\n",
    "        \n",
    "        # LSTM layer to process the embedded input sequences\n",
    "        self.rnn = nn.LSTM(input_size=emb_dim, hidden_size=hid_dim, num_layers=n_layers, dropout=dropout, batch_first=True)\n",
    "        \n",
    "        # Dropout layer to prevent overfitting\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \"\"\"\n",
    "        Forward pass of the encoder.\n",
    "        \n",
    "        Args:\n",
    "            src (torch.Tensor): Input tensor of shape (batch_size, seq_len)\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor from the LSTM layer of shape (batch_size, seq_len, hid_dim)\n",
    "            torch.Tensor: Final hidden state of the LSTM of shape (num_layers, batch_size, hid_dim)\n",
    "            torch.Tensor: Final cell state of the LSTM of shape (num_layers, batch_size, hid_dim)\n",
    "        \"\"\"\n",
    "        # Embed the input tokens\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        \n",
    "        # Pass the embedded sequences through the LSTM\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        \n",
    "        return outputs, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e74ebf53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:42.678693Z",
     "iopub.status.busy": "2024-05-26T02:40:42.678383Z",
     "iopub.status.idle": "2024-05-26T02:40:42.688375Z",
     "shell.execute_reply": "2024-05-26T02:40:42.687514Z"
    },
    "papermill": {
     "duration": 0.027422,
     "end_time": "2024-05-26T02:40:42.690344",
     "exception": false,
     "start_time": "2024-05-26T02:40:42.662922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hidden_dim, n_layers, dropout = 0.5):\n",
    "        \"\"\"\n",
    "        Decoder module of a sequence-to-sequence model.\n",
    "\n",
    "        Args:\n",
    "            output_dim (int): The size of the output vocabulary.\n",
    "            emb_dim (int): The dimensionality of the embedding layer.\n",
    "            hidden_dim (int): The dimensionality of the hidden states.\n",
    "            n_layers (int): The number of layers in the LSTM.\n",
    "            dropout (float): The dropout probability.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initialize decoder attributes\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        # Embedding layer to convert output tokens into dense vectors\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim, padding_idx=0)\n",
    "        \n",
    "        # LSTM layer to process the embedded output sequences\n",
    "        self.rnn = nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout, batch_first=True)\n",
    "        \n",
    "        # Fully connected layer to map LSTM output to output dimension\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim, bias = False)\n",
    "        \n",
    "        # Dropout layer to prevent overfitting\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, encoder_hidden, encoder_cell):\n",
    "        \"\"\"\n",
    "        Forward pass of the decoder.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size,)\n",
    "            encoder_hidden (torch.Tensor): Final hidden state of the encoder LSTM of shape (num_layers, batch_size, hid_dim)\n",
    "            encoder_cell (torch.Tensor): Final cell state of the encoder LSTM of shape (num_layers, batch_size, hid_dim)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of shape (batch_size, output_dim)\n",
    "            torch.Tensor: Hidden state tensor of shape (num_layers, batch_size, hidden_dim)\n",
    "            torch.Tensor: Cell state tensor of shape (num_layers, batch_size, hidden_dim)\n",
    "        \"\"\"\n",
    "        # Initialize the hidden and cell states with the encoder final states\n",
    "        hidden = encoder_hidden\n",
    "        cell = encoder_cell\n",
    "\n",
    "        # Embed the input tokens\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (batch_size, 1, emb_dim)\n",
    "\n",
    "        # Pass the embedded sequences through the LSTM\n",
    "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
    "        # outputs shape: (batch_size, 1, hidden_dim)\n",
    "\n",
    "        # Map LSTM output to output dimension\n",
    "        predictions = self.fc_out(outputs)\n",
    "        # predictions shape: (batch_size, 1, output_dim)\n",
    "\n",
    "        # Remove the unnecessary dimension\n",
    "        predictions = predictions.squeeze(1)\n",
    "        # predictions shape: (batch_size, output_dim)\n",
    "\n",
    "        return predictions, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b1c0ea1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:42.720137Z",
     "iopub.status.busy": "2024-05-26T02:40:42.719850Z",
     "iopub.status.idle": "2024-05-26T02:40:42.729359Z",
     "shell.execute_reply": "2024-05-26T02:40:42.728387Z"
    },
    "papermill": {
     "duration": 0.026999,
     "end_time": "2024-05-26T02:40:42.731443",
     "exception": false,
     "start_time": "2024-05-26T02:40:42.704444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        \"\"\"\n",
    "        Sequence-to-sequence model consisting of an encoder and a decoder.\n",
    "\n",
    "        Args:\n",
    "            encoder (Encoder): Encoder module.\n",
    "            decoder (Decoder): Decoder module.\n",
    "        \"\"\"\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio=0.8):\n",
    "        \"\"\"\n",
    "        Forward pass of the sequence-to-sequence model.\n",
    "\n",
    "        Args:\n",
    "            source (torch.Tensor): Input tensor of shape (batch_size, src_seq_len), (50 x 25) in our case.\n",
    "            target (torch.Tensor): Target tensor of shape (batch_size, tgt_seq_len), (50 x 25) in our case.\n",
    "            teacher_force_ratio (float, optional): Probability of using teacher forcing. Default: 0.8.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of shape (tgt_seq_len, batch_size, output_dim), (25, 50, 3060) in our case.\n",
    "        \"\"\"\n",
    "        batch_size = source.shape[0]\n",
    "        target_len = target.shape[1]\n",
    "        target_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        # Initialize outputs tensor to store decoder predictions\n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(source.device)\n",
    "\n",
    "        # Encode the source sequence\n",
    "        _, hidden, cell = self.encoder(source)\n",
    "\n",
    "        # Initialize the input to the decoder with the start token\n",
    "        x = target[:, 0].unsqueeze(1)\n",
    "\n",
    "        # Iterate over each token in the target sequence\n",
    "        for t in range(1, target_len):\n",
    "            # Use previous hidden and cell states as context from the encoder\n",
    "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
    "            # Store the decoder prediction\n",
    "            outputs[t] = output\n",
    "            # Determine the next input to the decoder using teacher forcing\n",
    "            x = target[:, t].unsqueeze(1) if random.random() < teacher_force_ratio else output.argmax(1).unsqueeze(1)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c8796ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:42.762034Z",
     "iopub.status.busy": "2024-05-26T02:40:42.761325Z",
     "iopub.status.idle": "2024-05-26T02:40:42.766610Z",
     "shell.execute_reply": "2024-05-26T02:40:42.765669Z"
    },
    "papermill": {
     "duration": 0.022842,
     "end_time": "2024-05-26T02:40:42.768505",
     "exception": false,
     "start_time": "2024-05-26T02:40:42.745663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize hyperparamenters\n",
    "INPUT_DIM = len(english_vocab)\n",
    "OUTPUT_DIM = len(nepali_vocab)\n",
    "ENC_EMB_DIM = 512\n",
    "DEC_EMB_DIM = 512\n",
    "HID_DIM = 1024\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "learning_rate = 0.0005\n",
    "\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5fe7a671",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:42.797886Z",
     "iopub.status.busy": "2024-05-26T02:40:42.797590Z",
     "iopub.status.idle": "2024-05-26T02:40:43.450100Z",
     "shell.execute_reply": "2024-05-26T02:40:43.449077Z"
    },
    "papermill": {
     "duration": 0.670053,
     "end_time": "2024-05-26T02:40:43.452562",
     "exception": false,
     "start_time": "2024-05-26T02:40:42.782509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize the encoders and decoders\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT).to(device)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64ff0691",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:43.482107Z",
     "iopub.status.busy": "2024-05-26T02:40:43.481775Z",
     "iopub.status.idle": "2024-05-26T02:40:43.489673Z",
     "shell.execute_reply": "2024-05-26T02:40:43.488801Z"
    },
    "papermill": {
     "duration": 0.024717,
     "end_time": "2024-05-26T02:40:43.491635",
     "exception": false,
     "start_time": "2024-05-26T02:40:43.466918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize sequence-to-sequence model, its optimizer and the loss\n",
    "model = Seq2Seq(enc, dec).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), weight_decay=1e-5)\n",
    "TRG_PAD_IDX = nepali_vocab['<pad>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc3c430c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:43.520530Z",
     "iopub.status.busy": "2024-05-26T02:40:43.520243Z",
     "iopub.status.idle": "2024-05-26T02:40:43.537207Z",
     "shell.execute_reply": "2024-05-26T02:40:43.536218Z"
    },
    "papermill": {
     "duration": 0.033666,
     "end_time": "2024-05-26T02:40:43.539087",
     "exception": false,
     "start_time": "2024-05-26T02:40:43.505421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, criterion, train_loader, val_loader, device, num_epochs, checkpoint_dir, patience=5, min_delta=0.0001):\n",
    "    \"\"\"\n",
    "    Train a sequence-to-sequence model using the specified data loaders.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The sequence-to-sequence model to be trained.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer used for training.\n",
    "        criterion (torch.nn.Module): The loss function used for training.\n",
    "        train_loader (torch.utils.data.DataLoader): Data loader for training data.\n",
    "        val_loader (torch.utils.data.DataLoader): Data loader for validation data.\n",
    "        device (torch.device): Device on which to perform computations (e.g., 'cpu' or 'cuda').\n",
    "        num_epochs (int): Number of epochs to train the model.\n",
    "        checkpoint_dir (str): Directory to save model checkpoints.\n",
    "        patience (int, optional): Number of epochs with no improvement after which training will be stopped. Default: 5.\n",
    "        min_delta (float, optional): Minimum change in the monitored quantity to qualify as an improvement. Default: 0.0001.\n",
    "    \"\"\"\n",
    "    for epoch in range(num_epochs):\n",
    "        # Create directory for saving checkpoints if it does not exist\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "\n",
    "        # Initialize variables for early stopping\n",
    "        best_loss = float('inf')\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        print(f\"[Epoch {epoch+1} / {num_epochs}]\")\n",
    "\n",
    "        # Set model to training mode\n",
    "        model.train()\n",
    "\n",
    "        train_loss = 0.0\n",
    "        for source, target in train_loader:\n",
    "            # Get input and targets and move to device\n",
    "            inp_data = source.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(inp_data, target, teacher_force_ratio=0.4)\n",
    "\n",
    "            # Reshape output and target for the loss function\n",
    "            output = output[1:].reshape(-1, output.shape[2])\n",
    "            target = target.t()[1:].reshape(-1) \n",
    "\n",
    "            # Zero gradients, compute loss, backpropagate, and update weights\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping to avoid exploding gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "            \n",
    "            # Gradient descent step\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Average training loss for the epoch\n",
    "        train_loss /= len(train_loader)\n",
    "        print(f\"Training loss: {train_loss:.4f}\")\n",
    "\n",
    "        # Set model to evaluation mode for validation\n",
    "        model.eval()\n",
    "\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for source, target in val_loader:\n",
    "                # Get input and targets and move to device\n",
    "                inp_data = source.to(device)\n",
    "                target = target.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                output = model(inp_data, target, teacher_force_ratio=0)\n",
    "\n",
    "                # Reshape output and target for the loss function\n",
    "                output = output[1:].reshape(-1, output.shape[2])\n",
    "                target = target.t()[1:].reshape(-1) \n",
    "\n",
    "                # Compute loss\n",
    "                loss = criterion(output, target)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        # Average validation loss for the epoch\n",
    "        val_loss /= len(val_loader)\n",
    "        print(f\"Validation loss: {val_loss:.4f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if train_loss < best_loss - min_delta:\n",
    "            best_loss = train_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f'Early stopping at epoch {epoch + 1}')\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f's2s_epoch_{epoch+1}.pth')\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f'Model saved to {checkpoint_path}')\n",
    "            break\n",
    "        \n",
    "        # Save model checkpoint every 25 epochs\n",
    "        if (epoch + 1) % 25 == 0:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f's2s_epoch_{epoch+1}.pth')\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f'Model saved to {checkpoint_path}')\n",
    "            \n",
    "        if (epoch == num_epochs - 1):\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f's2s_epoch_{epoch+1}.pth')\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f'Model saved to {checkpoint_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "711bae50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:40:43.568710Z",
     "iopub.status.busy": "2024-05-26T02:40:43.568386Z",
     "iopub.status.idle": "2024-05-26T02:48:33.091434Z",
     "shell.execute_reply": "2024-05-26T02:48:33.090254Z"
    },
    "papermill": {
     "duration": 469.539956,
     "end_time": "2024-05-26T02:48:33.093437",
     "exception": false,
     "start_time": "2024-05-26T02:40:43.553481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 / 100]\n",
      "Training loss: 5.7276\n",
      "Validation loss: 5.3816\n",
      "[Epoch 2 / 100]\n",
      "Training loss: 5.0995\n",
      "Validation loss: 5.4189\n",
      "[Epoch 3 / 100]\n",
      "Training loss: 4.9656\n",
      "Validation loss: 5.4481\n",
      "[Epoch 4 / 100]\n",
      "Training loss: 4.8668\n",
      "Validation loss: 5.5994\n",
      "[Epoch 5 / 100]\n",
      "Training loss: 4.8655\n",
      "Validation loss: 5.5355\n",
      "[Epoch 6 / 100]\n",
      "Training loss: 4.7833\n",
      "Validation loss: 5.5056\n",
      "[Epoch 7 / 100]\n",
      "Training loss: 4.7027\n",
      "Validation loss: 5.3222\n",
      "[Epoch 8 / 100]\n",
      "Training loss: 4.5653\n",
      "Validation loss: 5.3469\n",
      "[Epoch 9 / 100]\n",
      "Training loss: 4.4721\n",
      "Validation loss: 5.2834\n",
      "[Epoch 10 / 100]\n",
      "Training loss: 4.3984\n",
      "Validation loss: 5.3213\n",
      "[Epoch 11 / 100]\n",
      "Training loss: 4.2841\n",
      "Validation loss: 5.2513\n",
      "[Epoch 12 / 100]\n",
      "Training loss: 4.1392\n",
      "Validation loss: 5.1252\n",
      "[Epoch 13 / 100]\n",
      "Training loss: 4.0239\n",
      "Validation loss: 5.0873\n",
      "[Epoch 14 / 100]\n",
      "Training loss: 3.9018\n",
      "Validation loss: 5.1729\n",
      "[Epoch 15 / 100]\n",
      "Training loss: 3.7974\n",
      "Validation loss: 5.0258\n",
      "[Epoch 16 / 100]\n",
      "Training loss: 3.6619\n",
      "Validation loss: 5.1227\n",
      "[Epoch 17 / 100]\n",
      "Training loss: 3.5526\n",
      "Validation loss: 5.0648\n",
      "[Epoch 18 / 100]\n",
      "Training loss: 3.4292\n",
      "Validation loss: 5.0748\n",
      "[Epoch 19 / 100]\n",
      "Training loss: 3.3457\n",
      "Validation loss: 4.9585\n",
      "[Epoch 20 / 100]\n",
      "Training loss: 3.2178\n",
      "Validation loss: 5.0248\n",
      "[Epoch 21 / 100]\n",
      "Training loss: 3.1200\n",
      "Validation loss: 4.9322\n",
      "[Epoch 22 / 100]\n",
      "Training loss: 3.0208\n",
      "Validation loss: 4.9093\n",
      "[Epoch 23 / 100]\n",
      "Training loss: 2.9052\n",
      "Validation loss: 4.8723\n",
      "[Epoch 24 / 100]\n",
      "Training loss: 2.8230\n",
      "Validation loss: 4.8875\n",
      "[Epoch 25 / 100]\n",
      "Training loss: 2.6862\n",
      "Validation loss: 4.9555\n",
      "Model saved to /kaggle/working/s2s_epoch_25.pth\n",
      "[Epoch 26 / 100]\n",
      "Training loss: 2.5928\n",
      "Validation loss: 4.9078\n",
      "[Epoch 27 / 100]\n",
      "Training loss: 2.4740\n",
      "Validation loss: 4.8248\n",
      "[Epoch 28 / 100]\n",
      "Training loss: 2.3773\n",
      "Validation loss: 4.9439\n",
      "[Epoch 29 / 100]\n",
      "Training loss: 2.2517\n",
      "Validation loss: 4.9460\n",
      "[Epoch 30 / 100]\n",
      "Training loss: 2.1199\n",
      "Validation loss: 4.9367\n",
      "[Epoch 31 / 100]\n",
      "Training loss: 2.0617\n",
      "Validation loss: 4.8858\n",
      "[Epoch 32 / 100]\n",
      "Training loss: 1.9290\n",
      "Validation loss: 4.8768\n",
      "[Epoch 33 / 100]\n",
      "Training loss: 1.8280\n",
      "Validation loss: 5.0129\n",
      "[Epoch 34 / 100]\n",
      "Training loss: 1.7082\n",
      "Validation loss: 4.8802\n",
      "[Epoch 35 / 100]\n",
      "Training loss: 1.6410\n",
      "Validation loss: 4.9049\n",
      "[Epoch 36 / 100]\n",
      "Training loss: 1.5491\n",
      "Validation loss: 4.8819\n",
      "[Epoch 37 / 100]\n",
      "Training loss: 1.4399\n",
      "Validation loss: 5.0069\n",
      "[Epoch 38 / 100]\n",
      "Training loss: 1.3412\n",
      "Validation loss: 4.9473\n",
      "[Epoch 39 / 100]\n",
      "Training loss: 1.2490\n",
      "Validation loss: 4.9578\n",
      "[Epoch 40 / 100]\n",
      "Training loss: 1.1520\n",
      "Validation loss: 5.0540\n",
      "[Epoch 41 / 100]\n",
      "Training loss: 1.0603\n",
      "Validation loss: 5.0088\n",
      "[Epoch 42 / 100]\n",
      "Training loss: 1.0007\n",
      "Validation loss: 5.1132\n",
      "[Epoch 43 / 100]\n",
      "Training loss: 0.9079\n",
      "Validation loss: 5.1939\n",
      "[Epoch 44 / 100]\n",
      "Training loss: 0.8438\n",
      "Validation loss: 5.1186\n",
      "[Epoch 45 / 100]\n",
      "Training loss: 0.7493\n",
      "Validation loss: 5.2874\n",
      "[Epoch 46 / 100]\n",
      "Training loss: 0.6993\n",
      "Validation loss: 5.2856\n",
      "[Epoch 47 / 100]\n",
      "Training loss: 0.6264\n",
      "Validation loss: 5.3786\n",
      "[Epoch 48 / 100]\n",
      "Training loss: 0.5547\n",
      "Validation loss: 5.3646\n",
      "[Epoch 49 / 100]\n",
      "Training loss: 0.5101\n",
      "Validation loss: 5.4047\n",
      "[Epoch 50 / 100]\n",
      "Training loss: 0.4654\n",
      "Validation loss: 5.4123\n",
      "Model saved to /kaggle/working/s2s_epoch_50.pth\n",
      "[Epoch 51 / 100]\n",
      "Training loss: 0.4340\n",
      "Validation loss: 5.3509\n",
      "[Epoch 52 / 100]\n",
      "Training loss: 0.3695\n",
      "Validation loss: 5.5092\n",
      "[Epoch 53 / 100]\n",
      "Training loss: 0.3583\n",
      "Validation loss: 5.5871\n",
      "[Epoch 54 / 100]\n",
      "Training loss: 0.3206\n",
      "Validation loss: 5.5625\n",
      "[Epoch 55 / 100]\n",
      "Training loss: 0.3089\n",
      "Validation loss: 5.6341\n",
      "[Epoch 56 / 100]\n",
      "Training loss: 0.2892\n",
      "Validation loss: 5.6505\n",
      "[Epoch 57 / 100]\n",
      "Training loss: 0.2790\n",
      "Validation loss: 5.7159\n",
      "[Epoch 58 / 100]\n",
      "Training loss: 0.2438\n",
      "Validation loss: 5.7511\n",
      "[Epoch 59 / 100]\n",
      "Training loss: 0.2404\n",
      "Validation loss: 5.8111\n",
      "[Epoch 60 / 100]\n",
      "Training loss: 0.2167\n",
      "Validation loss: 5.7385\n",
      "[Epoch 61 / 100]\n",
      "Training loss: 0.2166\n",
      "Validation loss: 5.8040\n",
      "[Epoch 62 / 100]\n",
      "Training loss: 0.2085\n",
      "Validation loss: 5.7276\n",
      "[Epoch 63 / 100]\n",
      "Training loss: 0.1958\n",
      "Validation loss: 5.8317\n",
      "[Epoch 64 / 100]\n",
      "Training loss: 0.1781\n",
      "Validation loss: 5.7884\n",
      "[Epoch 65 / 100]\n",
      "Training loss: 0.1681\n",
      "Validation loss: 5.7633\n",
      "[Epoch 66 / 100]\n",
      "Training loss: 0.1646\n",
      "Validation loss: 5.8210\n",
      "[Epoch 67 / 100]\n",
      "Training loss: 0.1652\n",
      "Validation loss: 5.8424\n",
      "[Epoch 68 / 100]\n",
      "Training loss: 0.1550\n",
      "Validation loss: 5.9077\n",
      "[Epoch 69 / 100]\n",
      "Training loss: 0.1577\n",
      "Validation loss: 5.8847\n",
      "[Epoch 70 / 100]\n",
      "Training loss: 0.1557\n",
      "Validation loss: 5.9010\n",
      "[Epoch 71 / 100]\n",
      "Training loss: 0.1480\n",
      "Validation loss: 5.9022\n",
      "[Epoch 72 / 100]\n",
      "Training loss: 0.1513\n",
      "Validation loss: 6.0385\n",
      "[Epoch 73 / 100]\n",
      "Training loss: 0.1484\n",
      "Validation loss: 6.0840\n",
      "[Epoch 74 / 100]\n",
      "Training loss: 0.1519\n",
      "Validation loss: 5.9313\n",
      "[Epoch 75 / 100]\n",
      "Training loss: 0.1424\n",
      "Validation loss: 5.9938\n",
      "Model saved to /kaggle/working/s2s_epoch_75.pth\n",
      "[Epoch 76 / 100]\n",
      "Training loss: 0.1438\n",
      "Validation loss: 5.9280\n",
      "[Epoch 77 / 100]\n",
      "Training loss: 0.1412\n",
      "Validation loss: 6.0709\n",
      "[Epoch 78 / 100]\n",
      "Training loss: 0.1498\n",
      "Validation loss: 6.0357\n",
      "[Epoch 79 / 100]\n",
      "Training loss: 0.1465\n",
      "Validation loss: 5.9717\n",
      "[Epoch 80 / 100]\n",
      "Training loss: 0.1327\n",
      "Validation loss: 5.9969\n",
      "[Epoch 81 / 100]\n",
      "Training loss: 0.1361\n",
      "Validation loss: 5.9955\n",
      "[Epoch 82 / 100]\n",
      "Training loss: 0.1326\n",
      "Validation loss: 6.1484\n",
      "[Epoch 83 / 100]\n",
      "Training loss: 0.1251\n",
      "Validation loss: 6.0527\n",
      "[Epoch 84 / 100]\n",
      "Training loss: 0.1378\n",
      "Validation loss: 5.9597\n",
      "[Epoch 85 / 100]\n",
      "Training loss: 0.1365\n",
      "Validation loss: 6.0762\n",
      "[Epoch 86 / 100]\n",
      "Training loss: 0.1308\n",
      "Validation loss: 6.1102\n",
      "[Epoch 87 / 100]\n",
      "Training loss: 0.1337\n",
      "Validation loss: 6.1412\n",
      "[Epoch 88 / 100]\n",
      "Training loss: 0.1181\n",
      "Validation loss: 6.2124\n",
      "[Epoch 89 / 100]\n",
      "Training loss: 0.1156\n",
      "Validation loss: 6.2187\n",
      "[Epoch 90 / 100]\n",
      "Training loss: 0.1145\n",
      "Validation loss: 6.1545\n",
      "[Epoch 91 / 100]\n",
      "Training loss: 0.1096\n",
      "Validation loss: 6.1575\n",
      "[Epoch 92 / 100]\n",
      "Training loss: 0.1114\n",
      "Validation loss: 6.2040\n",
      "[Epoch 93 / 100]\n",
      "Training loss: 0.1069\n",
      "Validation loss: 6.2352\n",
      "[Epoch 94 / 100]\n",
      "Training loss: 0.1135\n",
      "Validation loss: 6.1002\n",
      "[Epoch 95 / 100]\n",
      "Training loss: 0.1037\n",
      "Validation loss: 6.1747\n",
      "[Epoch 96 / 100]\n",
      "Training loss: 0.1050\n",
      "Validation loss: 6.0882\n",
      "[Epoch 97 / 100]\n",
      "Training loss: 0.0987\n",
      "Validation loss: 6.1093\n",
      "[Epoch 98 / 100]\n",
      "Training loss: 0.1037\n",
      "Validation loss: 6.1610\n",
      "[Epoch 99 / 100]\n",
      "Training loss: 0.1057\n",
      "Validation loss: 5.9299\n",
      "[Epoch 100 / 100]\n",
      "Training loss: 0.1034\n",
      "Validation loss: 6.2430\n",
      "Model saved to /kaggle/working/s2s_epoch_100.pth\n",
      "Model saved to /kaggle/working/s2s_epoch_100.pth\n"
     ]
    }
   ],
   "source": [
    "train_model(model, optimizer, criterion, train_loader, valid_loader, device, epochs,'/kaggle/working/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f34fb02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:48:33.139201Z",
     "iopub.status.busy": "2024-05-26T02:48:33.138827Z",
     "iopub.status.idle": "2024-05-26T02:48:33.142920Z",
     "shell.execute_reply": "2024-05-26T02:48:33.142086Z"
    },
    "papermill": {
     "duration": 0.029328,
     "end_time": "2024-05-26T02:48:33.144857",
     "exception": false,
     "start_time": "2024-05-26T02:48:33.115529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_model = Seq2Seq(enc, dec).to(device)\n",
    "# PATH = '/kaggle/input/seq2seq_epoch_300_test/pytorch/test/1/s2s_epoch_300.pth'\n",
    "# test_model.load_state_dict(torch.load(PATH))\n",
    "# test_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9511327",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:48:33.190046Z",
     "iopub.status.busy": "2024-05-26T02:48:33.189514Z",
     "iopub.status.idle": "2024-05-26T02:48:33.197122Z",
     "shell.execute_reply": "2024-05-26T02:48:33.196306Z"
    },
    "papermill": {
     "duration": 0.032403,
     "end_time": "2024-05-26T02:48:33.199041",
     "exception": false,
     "start_time": "2024-05-26T02:48:33.166638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_sequences_batch(sequences, inv_vocab, sos_token, pad_token, eos_token):\n",
    "    decoded_sentences = []\n",
    "    for sequence in sequences:\n",
    "        sentence = []\n",
    "        for idx in sequence:\n",
    "            if idx == pad_token:  # Skip <pad> tokens\n",
    "                continue\n",
    "            if idx == sos_token:  # Skip <sos> tokens\n",
    "                continue\n",
    "            if idx == eos_token:\n",
    "                break\n",
    "            word = inv_vocab.get(idx.item(), f\"<unk:{idx.item()}>\")  # Get word from inv_vocab, handle unknowns\n",
    "            sentence.append(word)\n",
    "        decoded_sentences.append(' '.join(sentence))\n",
    "    return decoded_sentences\n",
    "\n",
    "# Define the decode_sequence function for decoding indices to words\n",
    "def decode_sequence(indices, vocab, eos_token, pad_token, sos_token):\n",
    "    sentence = []\n",
    "    for idx in indices:\n",
    "        if idx == eos_token:\n",
    "            break\n",
    "        if idx != pad_token and idx != sos_token:\n",
    "            sentence.append(vocab[idx])\n",
    "    return ' '.join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b2323fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:48:33.244555Z",
     "iopub.status.busy": "2024-05-26T02:48:33.243775Z",
     "iopub.status.idle": "2024-05-26T02:48:33.252072Z",
     "shell.execute_reply": "2024-05-26T02:48:33.251209Z"
    },
    "papermill": {
     "duration": 0.032876,
     "end_time": "2024-05-26T02:48:33.253923",
     "exception": false,
     "start_time": "2024-05-26T02:48:33.221047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def translate_sentences(model, valid_loader, device, target_vocab, inv_vocab):\n",
    "    translated_sentences = []\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for source, target in valid_loader:\n",
    "            # Move source and target to device\n",
    "            source = source.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # Forward pass through the model\n",
    "            output = model(source, target, teacher_force_ratio=0)\n",
    "            output = output.permute(1,0,2)\n",
    "\n",
    "            # Reshape output if necessary (output shape: batch_size, seq_len, vocab_size)\n",
    "            print(f'Output shape: {output.shape}')# Should be [50, 25, 2879]\n",
    "\n",
    "            # Get the predicted token indices for each sequence in the batch\n",
    "            predicted_indices = output.argmax(dim=2) # Shape: [50, 25]\n",
    "            print(predicted_indices.shape)\n",
    "\n",
    "            # Decode each sequence of indices\n",
    "            for indices in predicted_indices:\n",
    "                decoded_sentence = decode_sequence(indices.tolist(), inv_vocab, target_vocab['<eos>'], target_vocab['<sos>'], target_vocab['<pad>'])\n",
    "                translated_sentences.append(decoded_sentence)\n",
    "                \n",
    "            decoded_sentences_english = decode_sequences_batch(source, inv_english, english_vocab['<sos>'], english_vocab['<pad>'],  english_vocab['<eos>'])\n",
    "\n",
    "            # We break after the first batch for demonstration\n",
    "            break\n",
    "\n",
    "    return translated_sentences, decoded_sentences_english\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f0fb586",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T02:48:33.298971Z",
     "iopub.status.busy": "2024-05-26T02:48:33.298634Z",
     "iopub.status.idle": "2024-05-26T02:48:33.392833Z",
     "shell.execute_reply": "2024-05-26T02:48:33.391847Z"
    },
    "papermill": {
     "duration": 0.119465,
     "end_time": "2024-05-26T02:48:33.395173",
     "exception": false,
     "start_time": "2024-05-26T02:48:33.275708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([50, 25, 3060])\n",
      "torch.Size([50, 25])\n",
      "0)Source: what's your favorite kind of pizza ? \n",
      " Translated: यो चलचित्रमा तपाईलाई मूल्य पर्ने पात्र हो ? \n",
      "\n",
      "1)Source: i miss you badly . \n",
      " Translated: मलाई तिम्रो परोपकार याद आइरहेको छ । \n",
      "\n",
      "2)Source: it's not healthy to eat and run . \n",
      " Translated: यो संस्कृतिको बारेमा जान्न पाउँदा रमाइलो हुन्छ । \n",
      "\n",
      "3)Source: don't cry in public . \n",
      " Translated: बाहिर बाहिर नजानुहोस् । \n",
      "\n",
      "4)Source: tom doesn't seem to agree with you at all . \n",
      " Translated: टम तपाईंसँग बिलकुलै सहमत छैन जस्तो देखिन्छ । \n",
      "\n",
      "5)Source: tom is older than i thought . \n",
      " Translated: टम अझै पनि मेरो नाम हो । \n",
      "\n",
      "6)Source: aren't you allergic to anything ? \n",
      " Translated: के तपाइँ सोमबार एक्लै लोकप्रिय हुनुहुन्थ्यो ? \n",
      "\n",
      "7)Source: i don't know this part of town well . \n",
      " Translated: मलाई थाहा छैन तिमी के भन्दै छौ । \n",
      "\n",
      "8)Source: who's driving ? \n",
      " Translated: कसले गाउँदै छ ? \n",
      "\n",
      "9)Source: i'm pretty sure tom's competent . \n",
      " Translated: म टम क्यानेडियन हो भनेर पक्का छु । \n",
      "\n",
      "10)Source: i haven't decided what to do . \n",
      " Translated: मैले अझै के गर्ने निर्णय गरेको छैन । \n",
      "\n",
      "11)Source: she is quiet . \n",
      " Translated: उनी रोइरहेकी छिन् । \n",
      "\n",
      "12)Source: boston is a really beautiful place . \n",
      " Translated: बोस्टन एक साँच्चै सुन्दर स्थान हो । \n",
      "\n",
      "13)Source: how many billionaires are there in the world ? \n",
      " Translated: बस दिनमा कति पटक चल्छ ? \n",
      "\n",
      "14)Source: what have you seen so far ? \n",
      " Translated: तपाई आजकल के को लागी प्रयोग गर्नुहुन्छ ? \n",
      "\n",
      "15)Source: thank you ever so much . \n",
      " Translated: तिमीले धेरै धन्यवाद तिमीले । \n",
      "\n",
      "16)Source: my toolbox is in the trunk . \n",
      " Translated: मेरो जन्मदिन अक्टोबरमा हो । \n",
      "\n",
      "17)Source: who is heavier , tom or mary ? \n",
      " Translated: को अग्लो छ , टम वा मेरी ? \n",
      "\n",
      "18)Source: i am an artist . \n",
      " Translated: म ब्राजिलबाट हुँ । \n",
      "\n",
      "19)Source: she threatened him . \n",
      " Translated: उनलाई कफी मन पर्छ । \n",
      "\n",
      "20)Source: that dress is cheap . \n",
      " Translated: त्यो पुस्तक बिक्री भइसकेको छ । \n",
      "\n",
      "21)Source: tom was also offended . \n",
      " Translated: टमलाई जे गर्नुपर्छ त्यही गर्छन् । \n",
      "\n",
      "22)Source: i think that you're wrong . \n",
      " Translated: मलाई लाग्छ तपाईं एक महान हुनुहुन्छ । \n",
      "\n",
      "23)Source: i haven't decided yet whether i will attend the party . \n",
      " Translated: यदि म जान चाहन्छु कि भनेर मैले अझै निर्णय गरेको छैन । \n",
      "\n",
      "24)Source: you have to go back to australia . \n",
      " Translated: तपाईंले आफ्नो मोजाहरू फुकाउन आवश्यक छैन । \n",
      "\n",
      "25)Source: i must find the answer . \n",
      " Translated: यसको जवाफ मैले खोज्नुपर्छ । \n",
      "\n",
      "26)Source: people are dying . \n",
      " Translated: मान्छे मरिरहेका छन् । \n",
      "\n",
      "27)Source: i'm an addict . \n",
      " Translated: म भोलि बिदामा छु । \n",
      "\n",
      "28)Source: this is a list of products that we don't make anymore . \n",
      " Translated: यो एउटा कुकुर , एउटा बिरालो र तीनवटा क्यानरीहरू छन् । \n",
      "\n",
      "29)Source: we've already paid our rent . \n",
      " Translated: खाना खानु अघि आफ्नो हात धुनुहोस् । \n",
      "\n",
      "30)Source: he seems kind . \n",
      " Translated: उनी दयालु देखिन्छन् । \n",
      "\n",
      "31)Source: mount everest is the tallest mountain in the world . \n",
      " Translated: माउन्ट एभरेष्ट संसारको सबैभन्दा अग्लो चुचुरो हो । \n",
      "\n",
      "32)Source: i don't like sports . \n",
      " Translated: मलाई भिनेगर मन पर्दैन । \n",
      "\n",
      "33)Source: i eat meat . \n",
      " Translated: म माछा खान्छु । \n",
      "\n",
      "34)Source: the question is who will go there for tom . \n",
      " Translated: टम को छ , टम एभरेस्ट छ । \n",
      "\n",
      "35)Source: tom is a zoologist . \n",
      " Translated: टम एक प्रेमिका । \n",
      "\n",
      "36)Source: have my piece of cake if you like . \n",
      " Translated: मेरी आमा लागि धेरै कुरा थाहा छ । \n",
      "\n",
      "37)Source: tom apologized . \n",
      " Translated: टमले माफी मागे । \n",
      "\n",
      "38)Source: please come again . \n",
      " Translated: कृपया फेरि आउनुहोला । \n",
      "\n",
      "39)Source: when's father's day ? \n",
      " Translated: सुरु गरौँ कि ? \n",
      "\n",
      "40)Source: tom is my new roommate . \n",
      " Translated: टम मेरो पहिलो नाम हो । \n",
      "\n",
      "41)Source: who is tom to you ? \n",
      " Translated: जे भए पनि टम को हो ? \n",
      "\n",
      "42)Source: i don't have as much money as i used to have . \n",
      " Translated: मलाई लाग्दैन कि उनीहरूले अहिलेसम्म यसको उपचार फेला पारेका छन् । \n",
      "\n",
      "43)Source: i can't drive anywhere because my car's out of gas . \n",
      " Translated: म आज रातको किन्न भेट्टाउन सक्ने खान खान चाहन्छु । \n",
      "\n",
      "44)Source: don't underestimate my power . \n",
      " Translated: तिनीहरू मेरो टेलिभिजन नगर । \n",
      "\n",
      "45)Source: i'm a bit worried . \n",
      " Translated: म एक धनी बच्चा हुँ । \n",
      "\n",
      "46)Source: tom was waiting for someone outside . \n",
      " Translated: टम त्यतिबेला रूपमा नर्भस थियो । \n",
      "\n",
      "47)Source: i'm drinking water because i'm thirsty . \n",
      " Translated: म अर्को वर्ष फ्रान्सेली भाषा लिँदैछु । \n",
      "\n",
      "48)Source: tom is washing dishes . \n",
      " Translated: टम एकदमै बलियो छ । \n",
      "\n",
      "49)Source: i was too drunk to do that . \n",
      " Translated: टमले त्यसो त्यसो गर्न गर्ने हुनेछ । \n",
      "\n"
     ]
    }
   ],
   "source": [
    "translated_sentences, source_sentences = translate_sentences(model, valid_loader, device, nepali_vocab, inv_nepali)\n",
    "\n",
    "# Assuming translate_sentences returns a tuple of lists\n",
    "for i, (translated, source) in enumerate(zip(translated_sentences, source_sentences)):\n",
    "    print(f\"{i})Source: {source} \\n Translated: {translated} \\n\")\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5642a8ae",
   "metadata": {
    "papermill": {
     "duration": 0.022031,
     "end_time": "2024-05-26T02:48:33.439637",
     "exception": false,
     "start_time": "2024-05-26T02:48:33.417606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5066851,
     "sourceId": 8492467,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 47113,
     "sourceId": 56083,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 485.068635,
   "end_time": "2024-05-26T02:48:35.186080",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-26T02:40:30.117445",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
