{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7aba655",
   "metadata": {},
   "source": [
    "# Linear Regression Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd3cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df76db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = pd.read_csv(\"../datasets/housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6902710",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6817cd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_target = housing_df['median_house_value']\n",
    "housing_features_df = housing_df.drop(columns=['median_house_value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8b3ead",
   "metadata": {},
   "source": [
    "##### total_bedrooms contains null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05ce2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c389384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_features_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e578f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_np = np.array(housing_features_df['total_bedrooms'].dropna())\n",
    "kde = KernelDensity(bandwidth=35, kernel='gaussian')\n",
    "kde.fit(bed_np[:, np.newaxis])  # sklearn expects data in 2D array format\n",
    "\n",
    "# Generate points for plotting the KDE\n",
    "x_plot = np.linspace(min(bed_np), max(bed_np), 1000)\n",
    "log_dens = kde.score_samples(x_plot[:, np.newaxis])\n",
    "\n",
    "# Plot the data and the KDE\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(housing_features_df['total_bedrooms'], bins=30, kde=False, alpha=0.5, label='Histogram of data', stat = 'density')\n",
    "plt.plot(x_plot, np.exp(log_dens), label='Kernel Density Estimation', color = 'Red')\n",
    "plt.title('Kernel Density Estimation (KDE) Total Bedrooms')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad53393",
   "metadata": {},
   "source": [
    "##### Total Bedrooms feature is right skewed, so we replace the null values with the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c8ff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_features_df['total_bedrooms'].fillna(housing_features_df['total_bedrooms'].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673807f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_features_df.hist(figsize=(10, 8))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3ebed0",
   "metadata": {},
   "source": [
    "## Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368dda30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding categorical data\n",
    "\n",
    "# Extract the 'ocean_proximity' column\n",
    "ocean_proximity_column = housing_features_df['ocean_proximity']\n",
    "\n",
    "# Create an instance of LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the LabelEncoder to your categorical data and transform it\n",
    "encoded_labels = label_encoder.fit_transform(ocean_proximity_column)\n",
    "\n",
    "# Replace the original 'ocean_proximity' column with the encoded labels\n",
    "housing_features_df['ocean_proximity'] = encoded_labels\n",
    "\n",
    "housing_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057f44fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_feat = housing_features_df.copy(deep = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46fe6a6",
   "metadata": {},
   "source": [
    "### Checking for Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d66c4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def calc_vif(X):\n",
    "\n",
    "    # Calculating VIF\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variables\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "    return(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e5a10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deal_with_multicollinearity(x, threshold=10):\n",
    "    while True:\n",
    "        vif = calc_vif(x)\n",
    "        highest_VIF_variable = vif[vif['VIF'] > threshold].sort_values(by='VIF', ascending=False).head(1)['variables']\n",
    "        if not highest_VIF_variable.empty:\n",
    "            highest_VIF_variable = highest_VIF_variable.iloc[0] # Access the scalar value\n",
    "            x.drop(columns=highest_VIF_variable, axis=1, inplace=True)\n",
    "        else:\n",
    "            break\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e04d74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_feat_no_mutli_col = deal_with_multicollinearity(housing_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95786921",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_feat_no_mutli_col.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e436c9",
   "metadata": {},
   "source": [
    "###  Homoscedasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fe7c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(housing_feat_no_mutli_col, housing_target, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a8b227",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_residual(X_train, y_train, X_test, y_test):\n",
    "    num_cols = X_train.shape[1]\n",
    "    num_rows = (num_cols + 1) // 2  # Determine the number of rows for subplots\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=num_rows, ncols=2, figsize=(12, 6*num_rows))\n",
    "\n",
    "    for i, col in enumerate(X_train.columns):\n",
    "        row = i // 2\n",
    "        col = i % 2\n",
    "        test = LinearRegression(fit_intercept=True)\n",
    "        test.fit(X_train.iloc[:, i].values.reshape(-1, 1), y_train)\n",
    "        y_pred = test.predict(X_test.iloc[:, i].values.reshape(-1, 1))\n",
    "        # Calculate residuals\n",
    "        residuals = y_test - y_pred\n",
    "\n",
    "        # Create residual plot\n",
    "        axes[row, col].scatter(y_pred, residuals, alpha=0.5)\n",
    "        axes[row, col].axhline(y=0, color='red', linestyle='--')  # Add horizontal line at y=0\n",
    "        axes[row, col].set_title(f'Residual Plot for {X_train.columns[i]}')\n",
    "        axes[row, col].set_xlabel('Predicted Values')\n",
    "        axes[row, col].set_ylabel('Residuals')\n",
    "\n",
    "    # Hide any empty subplots\n",
    "    for i in range(num_cols, num_rows * 2):\n",
    "        fig.delaxes(axes.flatten()[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your DataFrame\n",
    "plot_residual(X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4775a8e9",
   "metadata": {},
   "source": [
    "##### Out of the 4 features, it seems housing_median_age fulfills the condition of Homoscedasticity, and the residual plot for the median income also seems to have constant variance, while the other's are heteroscedastic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb127fa",
   "metadata": {},
   "source": [
    "### Residual Normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6727cb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = LinearRegression()\n",
    "\n",
    "lin.fit(X_train['housing_median_age'].values.reshape(-1,1), y_train)\n",
    "y_pred_h = lin.predict(X_test['housing_median_age'].values.reshape(-1,1))\n",
    "\n",
    "lin.fit(X_train['median_income'].values.reshape(-1,1), y_train)\n",
    "y_pred_m = lin.predict(X_test['median_income'].values.reshape(-1,1))\n",
    "\n",
    "residuals_housing_median_age = y_test - y_pred_h\n",
    "residuals_median_income = y_test - y_pred_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30545095",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sm.qqplot(residuals_housing_median_age, line='r')\n",
    "plt.title('Residuals QQ plot for housing_median_age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cf522b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "residual_np = np.array(residuals_housing_median_age)\n",
    "kde = KernelDensity(bandwidth=30000, kernel='gaussian')\n",
    "kde.fit(residual_np[:, np.newaxis])  # sklearn expects data in 2D array format\n",
    "\n",
    "# Generate points for plotting the KDE\n",
    "x_plot = np.linspace(min(residual_np), max(residual_np), 1000)\n",
    "log_dens = kde.score_samples(x_plot[:, np.newaxis])\n",
    "\n",
    "# Plot the data and the KDE\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(residuals_housing_median_age, bins=30, density=True, alpha=0.5, label='Histogram of data')\n",
    "plt.plot(x_plot, np.exp(log_dens), label='Kernel Density Estimation')\n",
    "plt.title('Kernel Density Estimation (KDE) Residuals Housing Median Age')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5cb6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(residuals_median_income, line='r')\n",
    "plt.title('Residuals QQ plot for median_income')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7779d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_np = np.array(residuals_median_income)\n",
    "kde = KernelDensity(bandwidth=30000, kernel='gaussian')\n",
    "kde.fit(residual_np[:, np.newaxis])  # sklearn expects data in 2D array format\n",
    "\n",
    "# Generate points for plotting the KDE\n",
    "x_plot = np.linspace(min(residual_np), max(residual_np), 1000)\n",
    "log_dens = kde.score_samples(x_plot[:, np.newaxis])\n",
    "\n",
    "# Plot the data and the KDE\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(residuals_median_income, bins=30, density=True, alpha=0.5, label='Histogram of data')\n",
    "plt.plot(x_plot, np.exp(log_dens), label='Kernel Density Estimation')\n",
    "plt.title('Kernel Density Estimation (KDE) Residuals Median Income')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62dce81",
   "metadata": {},
   "source": [
    "##### Residual distribution for housing_median_age is slightly positively skewed, while residual distribution for median_income is mostly normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46edb1c3",
   "metadata": {},
   "source": [
    "###  Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbd4cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Durbin-Watson test for median_income\n",
    "durbin_watson_statistic = durbin_watson(residuals_median_income)\n",
    "\n",
    "# Print the Durbin-Watson statistic\n",
    "print(\"Durbin-Watson Statistic:\", durbin_watson_statistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bc1bec",
   "metadata": {},
   "source": [
    "##### As the value of the statistic is nearly 2 for both, we can assume there is no significant corelation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ad5e2a",
   "metadata": {},
   "source": [
    "## Fit linear, ridge, and lasso regression using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d13d7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_reg_housing_median_age = LinearRegression()\n",
    "ridge_reg_housing_median_age = Ridge(alpha=1.0)\n",
    "lasso_reg_housing_median_age = Lasso(alpha=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b246794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit housing_median_age data using normal linear regression, ridge regression and lasso regression\n",
    "linear_reg_housing_median_age.fit(X_train['housing_median_age'].values.reshape(-1,1), y_train)\n",
    "ridge_reg_housing_median_age.fit(X_train['housing_median_age'].values.reshape(-1,1), y_train)\n",
    "lasso_reg_housing_median_age.fit(X_train['housing_median_age'].values.reshape(-1,1), y_train)\n",
    "\n",
    "linear_pred_h = linear_reg_housing_median_age.predict(X_test['housing_median_age'].values.reshape(-1,1))\n",
    "ridge_pred_h = ridge_reg_housing_median_age.predict(X_test['housing_median_age'].values.reshape(-1,1))\n",
    "lasso_pred_h = lasso_reg_housing_median_age.predict(X_test['housing_median_age'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb3b443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for linear regression\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.scatter(x = X_test['housing_median_age'], y = y_test)\n",
    "plt.xlabel(\"Housing Median Age\")\n",
    "plt.ylabel('Predicted values')\n",
    "plt.title(\"Best fit line by normal Linear Regression\")\n",
    "plt.plot(X_test['housing_median_age'], linear_pred_h, color='red', label='Fitted line')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f97b48",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot for ridge regression\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.scatter(x = X_test['housing_median_age'], y = y_test)\n",
    "plt.xlabel(\"Housing Median Age\")\n",
    "plt.ylabel('Predicted values')\n",
    "plt.title(\"Best fit line by Ridge Regression\")\n",
    "plt.plot(X_test['housing_median_age'], ridge_pred_h, color='red', label='Fitted line')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bf6db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for lasso regression\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.scatter(x = X_test['housing_median_age'], y = y_test)\n",
    "plt.xlabel(\"Housing Median Age\")\n",
    "plt.ylabel('Predicted values')\n",
    "plt.title(\"Best fit line by Lasso Regression\")\n",
    "plt.plot(X_test['housing_median_age'], lasso_pred_h, color='red', label='Fitted line')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ea0321",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_reg_median_income = LinearRegression()\n",
    "ridge_reg_median_income = Ridge(alpha=1.0)\n",
    "lasso_reg_median_income = Lasso(alpha=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b93593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit median_income using normal linear regression, lasso regression and ridge regression\n",
    "\n",
    "linear_reg_median_income.fit(X_train['median_income'].values.reshape(-1,1), y_train)\n",
    "ridge_reg_median_income.fit(X_train['median_income'].values.reshape(-1,1), y_train)\n",
    "lasso_reg_median_income.fit(X_train['median_income'].values.reshape(-1,1), y_train)\n",
    "\n",
    "linear_pred_median_age = linear_reg_median_income.predict(X_test['median_income'].values.reshape(-1,1))\n",
    "ridge_pred_median_age = ridge_reg_median_income.predict(X_test['median_income'].values.reshape(-1,1))\n",
    "lasso_pred_median_age = lasso_reg_median_income.predict(X_test['median_income'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c4bb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear regression\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.scatter(x = X_test['median_income'], y = y_test)\n",
    "plt.xlabel(\"Median Income\")\n",
    "plt.ylabel('Predicted values')\n",
    "plt.title(\"Best fit line by normal Linear Regression\")\n",
    "plt.plot(X_test['median_income'], linear_pred_median_age, color='red', label='Fitted line')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464ec720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridge regression\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.scatter(x = X_test['median_income'], y = y_test)\n",
    "plt.xlabel(\"Median Income\")\n",
    "plt.ylabel('Predicted values')\n",
    "plt.title(\"Best fit line by Ridge Regression\")\n",
    "plt.plot(X_test['median_income'], ridge_pred_median_age, color='red', label='Fitted line')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dfe470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lasso regression\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.scatter(x = X_test['median_income'], y = y_test)\n",
    "plt.xlabel(\"Median Income\")\n",
    "plt.ylabel('Predicted values')\n",
    "plt.title(\"Best fit line by Lasso Regression\")\n",
    "plt.plot(X_test['median_income'], lasso_pred_median_age, color='red', label='Fitted line')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5351c1c9",
   "metadata": {},
   "source": [
    "#### Test lasso and ridge regression by keep large alpha value to see how the best fit line changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df59a4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg_test = Ridge(alpha=100000)\n",
    "lasso_reg_test = Lasso(alpha=100000)\n",
    "\n",
    "ridge_reg_test.fit(X_train['median_income'].values.reshape(-1,1), y_train)\n",
    "lasso_reg_test.fit(X_train['median_income'].values.reshape(-1,1), y_train)\n",
    "\n",
    "ridge_pred_test = ridge_reg_test.predict(X_test['median_income'].values.reshape(-1,1))\n",
    "lasso_pred_test = lasso_reg_test.predict(X_test['median_income'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8b7825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lasso regression\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.scatter(x = X_test['median_income'], y = y_test)\n",
    "plt.xlabel(\"Median Income\")\n",
    "plt.ylabel('Predicted values')\n",
    "plt.title(\"Best fit line by Lasso Regression with high value of alpha\")\n",
    "plt.plot(X_test['median_income'], lasso_pred_test, color='red', label='Fitted line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d562d09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lasso regression\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.scatter(x = X_test['median_income'], y = y_test)\n",
    "plt.xlabel(\"Median Income\")\n",
    "plt.ylabel('Predicted values')\n",
    "plt.title(\"Best fit line by Ridge Regression with high value of alpha\")\n",
    "plt.plot(X_test['median_income'], ridge_pred_test, color='red', label='Fitted line')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63a7102",
   "metadata": {},
   "source": [
    "##  Evaluation metrics for regression models from scratch (NumPy): MAE, MSE, RMSE, R squared, Adjusted R squared\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24915395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error_np(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Calculate Mean Absolute Error (MAE).\n",
    "    \n",
    "    Parameters:\n",
    "    - y_pred: numpy.ndarray\n",
    "        Predicted values.\n",
    "    - y_true: numpy.ndarray\n",
    "        True values.\n",
    "    \n",
    "    Returns:\n",
    "    - float\n",
    "        Mean Absolute Error.\n",
    "    \"\"\"\n",
    "    return np.mean(np.abs(y_pred - y_true))\n",
    "\n",
    "def mean_squared_error_np(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Calculate Mean Squared Error (MSE).\n",
    "    \n",
    "    Parameters:\n",
    "    - y_pred: numpy.ndarray\n",
    "        Predicted values.\n",
    "    - y_true: numpy.ndarray\n",
    "        True values.\n",
    "    \n",
    "    Returns:\n",
    "    - float\n",
    "        Mean Squared Error.\n",
    "    \"\"\"\n",
    "    return np.mean((y_pred - y_true)**2)\n",
    "\n",
    "def root_mean_squared_error_np(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Calculate Root Mean Squared Error (RMSE).\n",
    "    \n",
    "    Parameters:\n",
    "    - y_pred: numpy.ndarray\n",
    "        Predicted values.\n",
    "    - y_true: numpy.ndarray\n",
    "        True values.\n",
    "    \n",
    "    Returns:\n",
    "    - float\n",
    "        Root Mean Squared Error.\n",
    "    \"\"\"\n",
    "    return np.sqrt(mean_squared_error(y_pred, y_true))\n",
    "\n",
    "def r_squared_np(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Calculate the coefficient of determination (R^2).\n",
    "    \n",
    "    Parameters:\n",
    "    - y_pred: numpy.ndarray\n",
    "        Predicted values.\n",
    "    - y_true: numpy.ndarray\n",
    "        True values.\n",
    "    \n",
    "    Returns:\n",
    "    - float\n",
    "        Coefficient of determination (R^2).\n",
    "    \"\"\"\n",
    "    ss_residual = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_total = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    return 1 - (ss_residual / ss_total)\n",
    "\n",
    "def adjusted_r_squared_np(y_pred, y_true, num_features):\n",
    "    \"\"\"\n",
    "    Calculate the adjusted R^2 value.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_pred: numpy.ndarray\n",
    "        Predicted values.\n",
    "    - y_true: numpy.ndarray\n",
    "        True values.\n",
    "    - num_features: int\n",
    "        Number of features in the model.\n",
    "    \n",
    "    Returns:\n",
    "    - float\n",
    "        Adjusted R^2 value.\n",
    "    \"\"\"\n",
    "    n = len(y_true)\n",
    "    r2 = r_squared_np(y_pred, y_true)\n",
    "    return 1 - (1 - r2) * ((n - 1) / (n - num_features - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033fab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error_np(linear_pred_median_age, y_test)\n",
    "print(\"Mean Absolute Error, using NumPy:\", mae)\n",
    "\n",
    "mse = mean_squared_error_np(linear_pred_median_age, y_test)\n",
    "print(\"Mean Squared Error, using NumPy:\", mse)\n",
    "\n",
    "rmse = root_mean_squared_error_np(linear_pred_median_age, y_test)\n",
    "print(\"Root Mean Squared Error, using NumPy:\", rmse)\n",
    "\n",
    "r2 = r_squared_np(linear_pred_median_age, y_test)\n",
    "print(\"R-squared, using NumPy:\", r2)\n",
    "\n",
    "adj_r2 = adjusted_r_squared_np(linear_pred_median_age, y_test, 1)\n",
    "print(\"Adjusted R-squared, using NumPy:\", adj_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363f18d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_pred_median_age = linear_reg_median_income.predict(X_test['median_income'].values.reshape(-1,1))\n",
    "\n",
    "# Calculate R^2\n",
    "r2 = linear_reg_median_income.score(X_test['median_income'].values.reshape(-1,1), y_test)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(y_test, linear_pred_median_age)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y_test, linear_pred_median_age)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1a4d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test mean absolute error\n",
    "assert np.isclose(mean_absolute_error_np(linear_pred_median_age, y_test), mean_absolute_error(y_test, linear_pred_median_age)), \"Mean Absolute Error Failed\"\n",
    "\n",
    "# Test mean squared error\n",
    "assert np.isclose(mean_squared_error_np(linear_pred_median_age, y_test), mean_squared_error(y_test, linear_pred_median_age)), 'Mean Square Error Failed'\n",
    "\n",
    "# Test R-squared\n",
    "assert np.isclose(r_squared_np(linear_pred_median_age, y_test), linear_reg_median_income.score(X_test['median_income'].values.reshape(-1,1), y_test)), \"R square failed\"\n",
    "\n",
    "print(\"All tests passed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d070855",
   "metadata": {},
   "source": [
    "##  Using a different number of variables (at least 3 cases), compare the result of R squared and Adjusted R squared values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923a264f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "housing_features_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c98ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(housing_features_df, housing_target, test_size = 0.2, random_state = 42)\n",
    "test_coeff_of_determination = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4872865f",
   "metadata": {},
   "source": [
    "#### Calculate $R^2$ and adjusted $R^2$ Using 1 features, ie median_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09a4ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_coeff_of_determination.fit(X_train_r['median_income'].values.reshape(-1,1), y_train_r)\n",
    "y_pred = test_coeff_of_determination.predict(X_test_r['median_income'].values.reshape(-1,1))\n",
    "print(f\"R^2 value for 1 feature: {r_squared_np(y_pred, y_test_r)}\")\n",
    "print(f\"Adjusted R^2 value for 1 feature: {adjusted_r_squared_np(y_pred, y_test_r, 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178d8fb7",
   "metadata": {},
   "source": [
    "#### Calculate $R^2$ and adjusted $R^2$ Using 2 features, ie median_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42361c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_coeff_of_determination.fit(X_train_r.loc[:, ['median_income', 'ocean_proximity']], y_train_r)\n",
    "y_pred = test_coeff_of_determination.predict(X_test_r.loc[:, ['median_income', 'ocean_proximity']])\n",
    "print(f\"R^2 value for 1 feature: {r_squared_np(y_pred, y_test_r)}\")\n",
    "print(f\"Adjusted R^2 value for 1 feature: {adjusted_r_squared_np(y_pred, y_test_r, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbe0c81",
   "metadata": {},
   "source": [
    "#### Calculate $R^2$ and adjusted $R^2$ Using 3 features, ie median_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e072013",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_coeff_of_determination.fit(X_train_r.loc[:, ['median_income', 'ocean_proximity', 'population']], y_train_r)\n",
    "y_pred = test_coeff_of_determination.predict(X_test_r.loc[:, ['median_income', 'ocean_proximity', 'population']])\n",
    "print(f\"R^2 value for 1 feature: {r_squared_np(y_pred, y_test_r)}\")\n",
    "print(f\"Adjusted R^2 value for 1 feature: {adjusted_r_squared_np(y_pred, y_test_r, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e331f95",
   "metadata": {},
   "source": [
    "#### Calculate $R^2$ and adjusted $R^2$ Using 4 features, ie median_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504a3fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_coeff_of_determination.fit(X_train_r.loc[:, ['median_income', 'ocean_proximity', 'population', 'housing_median_age']], y_train_r)\n",
    "y_pred = test_coeff_of_determination.predict(X_test_r.loc[:, ['median_income', 'ocean_proximity', 'population', 'housing_median_age']])\n",
    "print(f\"R^2 value for 1 feature: {r_squared_np(y_pred, y_test_r)}\")\n",
    "print(f\"Adjusted R^2 value for 1 feature: {adjusted_r_squared_np(y_pred, y_test_r, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca65cef9",
   "metadata": {},
   "source": [
    "#### Calculate $R^2$ and adjusted $R^2$ Using 5 features, ie median_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fc5c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_coeff_of_determination.fit(X_train_r.loc[:, ['median_income', 'ocean_proximity', 'population', 'housing_median_age', 'longitude']], y_train_r)\n",
    "y_pred = test_coeff_of_determination.predict(X_test_r.loc[:, ['median_income', 'ocean_proximity', 'population', 'housing_median_age', 'longitude']])\n",
    "print(f\"R^2 value for 1 feature: {r_squared_np(y_pred, y_test_r)}\")\n",
    "print(f\"Adjusted R^2 value for 1 feature: {adjusted_r_squared_np(y_pred, y_test_r, 5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abfbcfe",
   "metadata": {},
   "source": [
    "#### Calculate $R^2$ and adjusted $R^2$ Using 9 features, ie median_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d3f9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_coeff_of_determination.fit(X_train_r, y_train_r)\n",
    "y_pred = test_coeff_of_determination.predict(X_test_r)\n",
    "print(f\"R^2 value for 9 feature: {r_squared_np(y_pred, y_test_r)}\")\n",
    "print(f\"Adjusted R^2 value for 9 feature: {adjusted_r_squared_np(y_pred, y_test_r, 9)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ad5a46",
   "metadata": {},
   "source": [
    "##### Although the difference is very small within our dataset of housing prices, we can still see the trend that as the number of features increases the value of $R^2$ and adjusted $R^2$ increases. While this is always the case for $R^2$ i.e. the value of $R^2$ always increases with the increase in the number of features even if the new added feature is completely unrelated to the final target variable, the same is not true for adjusted $R^2$ as it accounts for the degree of freedom while caluculating how much variability the model captures.\n",
    "##### The difference between the two can be seen more clearly in the line plot below of the different values of $R^2$ and adjusted $R^2$ as the number of features increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332c43ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic dataset with varying number of features\n",
    "np.random.seed(0)\n",
    "num_samples = 100\n",
    "num_features = 40\n",
    "X = np.random.randn(num_samples, num_features)\n",
    "coefficients = np.random.randn(40)  # Only 30 coefficients are used for y\n",
    "\n",
    "# Introduce noise to some features so that they are not related to y\n",
    "noise_features = 10  # Number of features to add noise to\n",
    "X[:, :noise_features] += np.random.normal(0, 1, size=(num_samples, noise_features))\n",
    "\n",
    "y = np.dot(X[:, :40], coefficients) + np.random.randn(num_samples)  # Linear relationship with noise\n",
    "\n",
    "# Fit Linear Regression models with increasing number of features\n",
    "r_squared_values = []\n",
    "adjusted_r_squared_values = []\n",
    "\n",
    "for i in range(1, num_features + 1):\n",
    "    X_subset = X[:, :i]  # Select first i features\n",
    "    model = LinearRegression().fit(X_subset, y)\n",
    "    y_pred = model.predict(X_subset)\n",
    "    r_squared = r_squared_np(y_pred, y)\n",
    "    n = len(y)\n",
    "    p = i\n",
    "    adjusted_r_squared = adjusted_r_squared_np(y_pred, y, i)\n",
    "    r_squared_values.append(r_squared)\n",
    "    adjusted_r_squared_values.append(adjusted_r_squared)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504fd4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot R-squared and Adjusted R-squared values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, num_features + 1), r_squared_values, label='R-squared', marker='o')\n",
    "plt.plot(range(1, num_features + 1), adjusted_r_squared_values, label='Adjusted R-squared', marker='o')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Score')\n",
    "plt.title('R-squared vs. Adjusted R-squared')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69523ef4",
   "metadata": {},
   "source": [
    "## Tune hyperparameters of the model using different hyperparameter techniques and find the conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5213b36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(housing_feat_no_mutli_col.drop(columns=['ocean_proximity']), housing_feat_no_mutli_col['ocean_proximity'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_model = Ridge()\n",
    "param_grid_ridge = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "ridge_grid_search = GridSearchCV(ridge_model, param_grid_ridge, cv=5, scoring='neg_mean_squared_error')\n",
    "ridge_grid_search.fit(X_train, y_train)\n",
    "\n",
    "ridge_random_search = RandomizedSearchCV(ridge_model, param_distributions=param_grid_ridge, n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "ridge_random_search.fit(X_train, y_train)\n",
    "\n",
    "# Lasso Regression\n",
    "lasso_model = Lasso()\n",
    "param_grid_lasso = {'alpha': [0.01, 0.1, 1, 10, 100, 200, 300, 400, 500, 1000]}\n",
    "lasso_grid_search = GridSearchCV(lasso_model, param_grid_lasso, cv=5, scoring='neg_mean_squared_error')\n",
    "lasso_grid_search.fit(X_train, y_train)\n",
    "\n",
    "lasso_random_search = RandomizedSearchCV(lasso_model, param_distributions=param_grid_lasso, n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "lasso_random_search.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate Ridge models\n",
    "ridge_best_model_grid = ridge_grid_search.best_estimator_\n",
    "ridge_best_model_random = ridge_random_search.best_estimator_\n",
    "ridge_mse_grid = mean_squared_error(y_test, ridge_best_model_grid.predict(X_test))\n",
    "ridge_mse_random = mean_squared_error(y_test, ridge_best_model_random.predict(X_test))\n",
    "\n",
    "# Evaluate Lasso models\n",
    "lasso_best_model_grid = lasso_grid_search.best_estimator_\n",
    "lasso_best_model_random = lasso_random_search.best_estimator_\n",
    "lasso_mse_grid = mean_squared_error(y_test, lasso_best_model_grid.predict(X_test))\n",
    "lasso_mse_random = mean_squared_error(y_test, lasso_best_model_random.predict(X_test))\n",
    "\n",
    "print(\"Best Alpha for Ridge Regression (Grid Search):\", ridge_grid_search.best_params_['alpha'])\n",
    "print(\"Best Alpha for Ridge Regression (Random Search):\", ridge_random_search.best_params_['alpha'])\n",
    "\n",
    "print(\"\\nBest Alpha for Lasso Regression (Grid Search):\", lasso_grid_search.best_params_['alpha'])\n",
    "print(\"Best Alpha for Lasso Regression (Random Search):\", lasso_random_search.best_params_['alpha'])\n",
    "\n",
    "\n",
    "print(\"Ridge Regression Results:\")\n",
    "print(\"Grid Search - Mean Squared Error:\", ridge_mse_grid)\n",
    "print(\"Random Search - Mean Squared Error:\", ridge_mse_random)\n",
    "\n",
    "print(\"\\nLasso Regression Results:\")\n",
    "print(\"Grid Search - Mean Squared Error:\", lasso_mse_grid)\n",
    "print(\"Random Search - Mean Squared Error:\", lasso_mse_random)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
